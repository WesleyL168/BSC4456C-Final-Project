---
title: "Final Project Submission"
author: "Wesley Lim"
date: "2022-11-20"
output: html_document
---
```{r setup, include=FALSE} 
## Setup
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(reticulate)
library(tidyverse)
library(tidytuesdayR)
use_virtualenv("r-reticulate")
virtualenv_exists()
virtualenv_root()
py_install("pandas")
py_install("matplotlib")
```

This dataset deals with untidy, raw data for recording global plastic pollution. [https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-01-26/readme.md]
This data set contains data about global plastic pollution in the years 2019-2020. The data can be categorized by plastic type, country of cleanup, and source of plastic. While the data isn't necessarily an accurate representative of plastic pollution, it can give a glimpse into the situation given increasing environmental concerns.

In this project, I aimed to use R to tidy up the data and present statistical tests and graphical representations. At the same time, I attempted to learn python and use its PANDAS package to perform the same tasks if available.

Here, I loaded the dataset and got a sense of what I am working with. Verrry untidy data at first glance.

```{r}
## R
plastics <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-01-26/plastics.csv')
glimpse(plastics)
```

```{python}
## Python
import pandas as pd
plastics = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-01-26/plastics.csv')
plastics.head()

```


Below, I created different objects to group the data set by, creating different perspectives. I focused on more recent 2020 data.

This shows the top 10 countries with the most number of companies traced as sources of plastic collected. Countries with large economies like USA and China are among the top 10, which makes sense as they would likely be the highest producer and consumers of plastic. However, this does not indicate WHERE the plastic may end up being collected.
```{r}
## R
plastics_TP_2020 <- plastics %>%
  filter(year == 2020) %>%
  group_by(country) %>%
  count(country) %>%
  filter(n > 130)

ggplot(plastics_TP_2020, aes(x = reorder(country, -n), y = n)) +
  geom_col() +
  theme_classic() +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  ggtitle("Number of companies linked to plastic source") +
  xlab("Country") +
  ylab("Number of companies")
  

```


This python code is something I have been trying to solve for the last week of class, but haven't been able to solve. Even after following multiple guides, I don't seem to be able to download and install Tcl for this code to knit properly. However, this graph that shows number of total plastic count for all countries is able to run on in Rstudio.
```{python}
##Python

# plastics_2020 = plastics.query('year == 2020')
# 
# plastics_2020_T1 = plastics_2020.drop(columns=["num_events","volunteers","parent_company","year"])
# plastics_2020_T1 = plastics_2020_T1.groupby(["country"]).describe()
# plastics_2020_T1.head()
# 
# plastics_2020_total = plastics_2020.filter(items = ["country","grand_total"])
# plastics_2020_total = plastics_2020_total.groupby(["country"]).sum()
# plastics_2020_total.plot.bar()

```



Next, I tried to see if there is any correlation with percentage plastic type for each country. We see that only Nigeria and Indonesia overlap between this chart and the previous. This suggests that a lot of plastic collected in Nigeria and Indonesia can be traced back to their own companies. This also implies that major economies like USA and China are producing a lot of plastic and most can be traced to other less developed nations (the possibility of under representation in major countries like USA and China also exists). 
```{r}
## R
plastics_GT_2020 <- plastics %>%
  filter(year == 2020) %>%
  select(country,grand_total) %>%
  group_by(country) %>%
  summarize(Total = sum(grand_total)) %>%
  filter(Total > 8500)

ggplot(plastics_GT_2020, aes(x = reorder(country, -Total), y = Total)) +
  geom_col() +
  theme_classic() +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  ggtitle("Number of plastic collected") +
  xlab("Country") +
  ylab("Total plastic collected")


```



Up to this point, I realized that the data can be extremely biased since it relies on feedback from plastic clean up organizations. Not every country is given the same resources to track and clean up plastic pollution. 

The chart below shows the number of volunteers participated in each country versus the total amount of plastic collected. Nigeria, once again, is distinct from the other countries. Nigeria saw a large number of volunteers participating in the clean up and resulted in a high amount of plastics collected, a clear positive correlation between total amount of plastic collected to amount of volunteers. This correlation is observed with the USA and a majority of nations in the lower range.

However, Switzerland, Philippines, and China don't seem to follow this correlation. This could be the case in low plastic collection rate for 2020 (in China's case, which seems odd), or high plastic pollution in Switzerland and Philippines.
```{r}
## R
plastics_VC_2020 <- plastics %>%
  filter(year == 2020) %>%
  select(country, volunteers, grand_total) %>%
  group_by(country) %>%
  filter(volunteers != "NA", grand_total != "NA", country != "EMPTY") %>%
  summarise_all(sum)

ggplot(plastics_VC_2020, aes(x =volunteers,y=grand_total, label=country)) +
  geom_point() +
  geom_text(aes(label=ifelse(grand_total>20000,as.character(country),'')),size = 3.5, vjust = 1.5) +
  geom_text(aes(label=ifelse(volunteers>100000,as.character(country),'')),size = 3.5, vjust = 1.5) +
  theme_classic() +
  ggtitle("Total number of volunteers vs Total number of plastic collected") +
  xlab("Number of Volunteers") +
  ylab("Total number of plastic collected")


```

Here, I calculated the percentage plastic type for each country. The first table contains total count for each plastic type. The second table contains the percentage of each plastic type out of the grand total amount. For simplicity, I limited to the top 10 countries with the most amount of plastics. Two stacked bar charts were created. The first showed plastic type relative to total amount of plastics collect, whereas the second highlighted the distribution of plastic types in the top 10 nations.

```{r}
## R
plastics_PT_2020 <- plastics %>%
  filter(year == 2020) %>%
  select(country,grand_total,hdpe,ldpe,o,pet,pp,ps,pvc) %>%
  group_by(country) %>%
  summarise_all(sum)

head(plastics_PT_2020)

plastics_PT_2020_percent <- plastics_PT_2020 %>%
  mutate(hdpe = (hdpe/grand_total)*100) %>%
  mutate(ldpe = (ldpe/grand_total)*100) %>%
  mutate(o = (o/grand_total)*100) %>%
  mutate(pet = (pet/grand_total)*100) %>%
  mutate(pp = (pp/grand_total)*100) %>%
  mutate(ps = (ps/grand_total)*100) %>%
  mutate(pvc = (pvc/grand_total)*100) %>%
  mutate(total_percent = (hdpe + ldpe + o + pet + pp + ps + pvc)) %>%
filter(grand_total != "NA") %>%
filter(grand_total > 8500) %>%
pivot_longer(
  cols = c(hdpe,ldpe,o,pet,pp,ps,pvc),
  names_to = "type",
  values_to = "Percent"
)

head(plastics_PT_2020_percent)

ggplot(plastics_PT_2020_percent, aes(x=reorder(country, -grand_total), y = grand_total,fill=type)) +
  geom_col() +
  theme_classic() +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  labs(fill = "Plastic type", x = "Country", y = "Total plastic collected", title = "Nations with most plastic count by plastic type")

ggplot(plastics_PT_2020_percent, aes(x=country,y= (total_percent/7), fill=type)) +
  geom_col() +
  theme_classic() +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  labs(fill = "Plastic type", x = "Country", y = "Total percent", title = "Nations with most plastic count by plastic type")
```


Overall I enjoyed working on this final project.I wish I dived deeper into the data beforehand since I didn't get to do much statistical analysis. While this project didn't result in the goal of using python too much to analyze data, I found that R was much better suited for visual representation of data. With python, I liked the easy access of creating quick descriptions with PANDAS and sorting data. I'd imagine I would continue to use R for pure data analysis and sorting through experimental data, but I will love to keep learning to write programs with python to write code to supplement research work.